@article{Kingma2014,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy},
eprint = {1412.6980},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:pdf},
month = {dec},
title = {{Adam: A Method for Stochastic Optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2014}
}
@article{Vinyals2014,
abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
archivePrefix = {arXiv},
arxivId = {1409.3215},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
eprint = {1409.3215},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever, Vinyals, Le - 2014 - Sequence to Sequence Learning with Neural Networks.pdf:pdf},
month = {sep},
title = {{Sequence to Sequence Learning with Neural Networks}},
url = {http://arxiv.org/abs/1409.3215},
year = {2014}
}
@article{Hinton2012,
author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara and Kingsbury, Brian},
doi = {10.1109/MSP.2012.2205597},
file = {:C$\backslash$:/Users/Gonzalo/Documents/Universidad/Inteligencia Artificial/Visi{\'{o}}n Artificial/M2/Biblio/hinton2012.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
month = {nov},
number = {6},
pages = {82--97},
title = {{Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups}},
url = {http://ieeexplore.ieee.org/document/6296526/},
volume = {29},
year = {2012}
}
@article{Redmon2015,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
archivePrefix = {arXiv},
arxivId = {1506.02640},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
eprint = {1506.02640},
file = {:C$\backslash$:/Users/Gonzalo/Documents/Universidad/Inteligencia Artificial/Visi{\'{o}}n Artificial/M2/Biblio/1506.02640.pdf:pdf},
month = {jun},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
url = {http://arxiv.org/abs/1506.02640},
year = {2015}
}
@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
eprint = {1406.2661},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:pdf},
pages = {1--9},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}
@article{Ishaan2017,
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
archivePrefix = {arXiv},
arxivId = {1704.00028},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
eprint = {1704.00028},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gulrajani et al. - 2017 - Improved Training of Wasserstein GANs.pdf:pdf},
month = {mar},
number = {CoRR},
title = {{Improved Training of Wasserstein GANs}},
url = {http://arxiv.org/abs/1704.00028},
year = {2017}
}
@article{Neff2017,
abstract = {In recent years, deep learning based methods achieved state-of-the-art performance in most computer vision tasks. However, these methods are typically supervised, and require huge amounts of annotated data to train. Acquisition of annotated data can be a costly endeavour, especially for pixelwise methods such as image segmentation. To circumvent these costs and train on smaller datasets, data augmentation is commonly used to artifi- cially generate additional training data. A major downside of standard data augmentation methods is that they require knowledge of the underlying task in order to perform well, and introduce additional hyperparameters into the deep learning setup. To improve on these issues, we propose a novel method of data augmentation utilizing Generative Adversarial Networks (GANs). By modifying the GAN-formulation to gener- ate image-segmentation pairs, we can train a generative model that synthesizes new images and their corresponding segmentation masks from random noise. These synthetic image- segmentation pairs can then further be used to train segmentation networks, effectively acting as a data augmentation method. We evaluate our method on two image segmentation tasks: medical image segmen- tation of the left lung of the SCR Lung Database and semantic segmentation of the Cityscapes dataset. For the medical segmentation task, we show that our GAN-based augmentation performs as well as standard data augmentation, and training on purely synthetic data even outperforms our previously published results. For the Cityscapes eval- uation, we report that our GAN-based augmentation scheme is competitive with standard data augmentation methods, only performing slightly worse. We show synthetic image- segmentation pairs for both datasets and demonstrate that even for complex datasets such as Cityscapes, our GAN manages to generate reasonable synthetic data, suggesting that GAN-based augmentation has potential for future research.},
author = {Neff, Thomas},
file = {:C$\backslash$:/Users/Gonzalo/Documents/Universidad/Inteligencia Artificial/Visi{\'{o}}n Artificial/M2/2018{\_}03{\_}DA{\_}neff.pdf:pdf},
journal = {Arxiv},
keywords = {data augmentation,gan,image classification},
number = {March},
title = {{Data Augmentation in Deep Learning using Generative Adversarial Networks}},
year = {2017}
}
@article{Li2018,
abstract = {White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80{\%}, 84{\%} and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.},
author = {Li, Hongwei and Jiang, Gongfa and Zhang, Jianguo and Wang, Ruixuan and Wang, Zhaolei and Zheng, Wei Shi and Menze, Bjoern},
doi = {10.1016/j.neuroimage.2018.07.005},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Brain lesion segmentation,Deep learning,Ensemble models,MICCAI WMH segmentation challenge,White matter hyperintensities},
month = {dec},
pages = {650--665},
title = {{Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811918305974},
volume = {183},
year = {2018}
}
@inproceedings{Nie2017,
abstract = {Computed tomography (CT) is critical for various clinical applications, e.g., radiotherapy treatment planning and also PET attenuation correction. However, CT exposes radiation during acquisition, which may cause side effects to patients. Compared to CT, magnetic resonance imaging (MRI) is much safer and does not involve any radiations. Therefore, recently, researchers are greatly motivated to estimate CT image from its corresponding MR image of the same subject for the case of radiotherapy planning. In this paper, we propose a data-driven approach to address this challenging problem. Specifically, we train a fully convolutional network to generate CT given an MR image. To better model the nonlinear relationship from MRI to CT and to produce more realistic images, we propose to use the adversarial training strategy and an image gradient difference loss function. We further apply AutoContext Model to implement a context-aware generative adversarial network. Experimental results show that our method is accurate and robust for predicting CT images from MRI images, and also outperforms three state-of-the-art methods under comparison.},
author = {Nie, Dong and Trullo, Roger and Lian, Jun and Petitjean, Caroline and Ruan, Su and Wang, Qian and Shen, Dinggang},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66179-7_48},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nie et al. - 2017 - Medical image synthesis with context-aware generative adversarial networks.pdf:pdf},
isbn = {9783319661780},
issn = {16113349},
keywords = {Auto-context,Deep learning,GAN,Generative models,Image synthesis},
pages = {417--425},
publisher = {Springer Verlag},
title = {{Medical image synthesis with context-aware generative adversarial networks}},
volume = {10435 LNCS},
year = {2017}
}
