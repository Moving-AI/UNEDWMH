@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
eprint = {1406.2661},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:pdf},
pages = {1--9},
title = {{Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1406.2661},
year = {2014}
}
@article{Ishaan2017,
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
archivePrefix = {arXiv},
arxivId = {1704.00028},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
eprint = {1704.00028},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gulrajani et al. - 2017 - Improved Training of Wasserstein GANs.pdf:pdf},
month = {mar},
number = {CoRR},
title = {{Improved Training of Wasserstein GANs}},
url = {http://arxiv.org/abs/1704.00028},
year = {2017}
}
@article{Li2018,
abstract = {White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80{\%}, 84{\%} and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.},
author = {Li, Hongwei and Jiang, Gongfa and Zhang, Jianguo and Wang, Ruixuan and Wang, Zhaolei and Zheng, Wei Shi and Menze, Bjoern},
doi = {10.1016/j.neuroimage.2018.07.005},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Brain lesion segmentation,Deep learning,Ensemble models,MICCAI WMH segmentation challenge,White matter hyperintensities},
month = {dec},
pages = {650--665},
title = {{Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811918305974},
volume = {183},
year = {2018}
}
@article{Neff2017,
abstract = {In recent years, deep learning based methods achieved state-of-the-art performance in most computer vision tasks. However, these methods are typically supervised, and require huge amounts of annotated data to train. Acquisition of annotated data can be a costly endeavour, especially for pixelwise methods such as image segmentation. To circumvent these costs and train on smaller datasets, data augmentation is commonly used to artifi- cially generate additional training data. A major downside of standard data augmentation methods is that they require knowledge of the underlying task in order to perform well, and introduce additional hyperparameters into the deep learning setup. To improve on these issues, we propose a novel method of data augmentation utilizing Generative Adversarial Networks (GANs). By modifying the GAN-formulation to gener- ate image-segmentation pairs, we can train a generative model that synthesizes new images and their corresponding segmentation masks from random noise. These synthetic image- segmentation pairs can then further be used to train segmentation networks, effectively acting as a data augmentation method. We evaluate our method on two image segmentation tasks: medical image segmen- tation of the left lung of the SCR Lung Database and semantic segmentation of the Cityscapes dataset. For the medical segmentation task, we show that our GAN-based augmentation performs as well as standard data augmentation, and training on purely synthetic data even outperforms our previously published results. For the Cityscapes eval- uation, we report that our GAN-based augmentation scheme is competitive with standard data augmentation methods, only performing slightly worse. We show synthetic image- segmentation pairs for both datasets and demonstrate that even for complex datasets such as Cityscapes, our GAN manages to generate reasonable synthetic data, suggesting that GAN-based augmentation has potential for future research.},
author = {Neff, Thomas},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neff - 2017 - Data Augmentation in Deep Learning using Generative Adversarial Networks.pdf:pdf},
journal = {Arxiv},
keywords = {data augmentation,gan,image classification},
number = {March},
title = {{Data Augmentation in Deep Learning using Generative Adversarial Networks}},
year = {2017}
}
@inproceedings{Nie2017,
abstract = {Computed tomography (CT) is critical for various clinical applications, e.g., radiotherapy treatment planning and also PET attenuation correction. However, CT exposes radiation during acquisition, which may cause side effects to patients. Compared to CT, magnetic resonance imaging (MRI) is much safer and does not involve any radiations. Therefore, recently, researchers are greatly motivated to estimate CT image from its corresponding MR image of the same subject for the case of radiotherapy planning. In this paper, we propose a data-driven approach to address this challenging problem. Specifically, we train a fully convolutional network to generate CT given an MR image. To better model the nonlinear relationship from MRI to CT and to produce more realistic images, we propose to use the adversarial training strategy and an image gradient difference loss function. We further apply AutoContext Model to implement a context-aware generative adversarial network. Experimental results show that our method is accurate and robust for predicting CT images from MRI images, and also outperforms three state-of-the-art methods under comparison.},
author = {Nie, Dong and Trullo, Roger and Lian, Jun and Petitjean, Caroline and Ruan, Su and Wang, Qian and Shen, Dinggang},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66179-7_48},
file = {:C$\backslash$:/Users/Gonzalo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nie et al. - 2017 - Medical image synthesis with context-aware generative adversarial networks.pdf:pdf},
isbn = {9783319661780},
issn = {16113349},
keywords = {Auto-context,Deep learning,GAN,Generative models,Image synthesis},
pages = {417--425},
publisher = {Springer Verlag},
title = {{Medical image synthesis with context-aware generative adversarial networks}},
volume = {10435 LNCS},
year = {2017}
}
